# 爬虫基础教程

[TOC]

## 基础

```python
# encoding: utf-8
from urllib.request import urlopen
import re
html = urlopen(
    "https://mofanpy.com/static/scraping/basic-structure.html").read().decode('utf-8')
res = re.findall(r'<title>(.*?)</title>', html)
print(res[0])

res = re.findall(r'<p>(.*?)</p>', html, flags=re.DOTALL) # flags=re.DOTALL,选择多行信息
print(res[0])

res = re.findall(r'href="(.*?)"', html)
print(res)
```



## `BeautifulSoup`解析网页

`beautifulsoup`：简化，选取网页信息，代替re。

[官方中文文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)

```python
from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen(
    "https://mofanpy.com/static/scraping/basic-structure.html")\
    .read().decode('utf-8')

soup = BeautifulSoup(html, features='lxml')
# have several parser ways


print(soup.a)
# print(soup.find_all('a'))
all_href = soup.find_all('a')
for l in all_href:
    print(l['href'])
```

- **利用`CSS`的`Class`**

```python

html = urlopen(
    "https://mofanpy.com/static/scraping/list.html")\
    .read().decode('utf-8')

print(html)

soup = bs(html, features='lxml')

month = soup.find_all('li', {'class': 'month'})
for m in month:
    print(m.get_text())

jan = soup.find('ul', {'class':'jan'})
d_jan = jan.find_all('li')
for d in d_jan:
    print(d.get_text())
```

**爬百度百科的一个小栗子**

```python
# encoding: utf-8
from urllib.request import urlopen
from bs4 import BeautifulSoup
import re
import random

base_url = 'https://baike.baidu.com'
his = ['/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/5162711']

for t in range(20):

    url = base_url + his[-1]
    print(url)
    html = urlopen(url).read().decode('utf-8')
    soup = BeautifulSoup(html, features='lxml')
    print(t, soup.h1)
    sub_urls = soup.find_all('a',
                             {
                                 'target': '_blank',
                                 'href': re.compile(r'/item/(%.{2})+$')
                             })

    if len(sub_urls):
        his.append(random.sample(sub_urls, 1)[0]['href'])
    else:
        his.pop()
print(his)
```



## 多功能Request

加载网页时，有几种类型(`POST`,`GET`)等。

- `get`
  - 正常打开网页
  - 不往服务器传数据
- `post`
  - 账号登陆
  - 上传内容
  - 往服务器传数据

上传图片：

```python
param = {'wd': '莫烦python'}
r = requests.get('http://www.baidu.com', params=param)
# webbrowser.open(r.url)
file = {'uploadFile': open('./image.png', 'rb')}
r = requests.post('http://pythonscraping.com/pages/files/processing2.php', files=file)
print(r.text)
```

登录：

```python
load = {'username': 'test', 'password': 'password'}
r = requests.post(
    'http://pythonscraping.com/pages/cookies/login.html',
    data = load
)
print(r.cookies.get_dict())
r = requests.get('http://pythonscraping.com/pages/cookies/login.html',
                 cookies=r.cookies)
print(r.text)

```

使用Session登录：

```python
# login - session
session = requests.session()
payload = {'username': 'test', 'password': 'password'}
r = session.post('http://pythonscraping.com/pages/cookies/login.html',
                 data=payload)
print(r.cookies.get_dict())
r = session.get('http://pythonscraping.com/pages/cookies/login.html')
print(r.text)
```



## 下载文件

```python
from urllib.request import urlopen, urlretrieve
import requests

imgae_url = 'https://c-ssl.duitang.com/uploads/item/201509/21/20150921115800_KdTcs.thumb.1000_0.jpeg'

# use urlretrieve
urlretrieve(imgae_url, './img/image.png')

# use requests
r = requests.get(imgae_url)
with open('./img/image2.png', 'wb') as f:
    f.write(r.content)

# use requests - big file
r = requests.get(imgae_url, stream=True)
with open('./img/image3.png', 'wb') as f:
    for chunk in r.iter_content(chunk_size=32):
        f.write(chunk)
```

